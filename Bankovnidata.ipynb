{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popis datasetu \n",
    "\n",
    "Využívaná data se týkají přímých marketingových kampaní portugalské banky (Portuguese banking institution). Marketingové kampaně byly realizovány přes telefonní hovory. V několika případech bylo nutné uskutečnit kontakt s klientem vícekrát, pro zjistění, zda došlo k otevření a často bylo třeba provést více než jeden kontakt se stejným klientem, aby bylo možné zjistit, zda byl termínovaný vklad sjednán. \n",
    "\n",
    "Zdroj: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Načtění csv souboru do pandas DataFrame a výpis prvních 10 řádků\n",
    "\n",
    "df = pd.read_csv('./data/bank-additional-full.csv', sep=\";\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zobrazení počtu řádků a sloupců\n",
    "print(\"Rows count: \", df.shape[0])\n",
    "print(\"Columns count: \", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datový soubor obsahuje 20 proměnných, \n",
    "- 10 numerických \n",
    "- 10 kategorických \n",
    "a jednu cílovou proměnnou \"y\", která určuje, zda klient sjednal termínovaný vklad a dosahuje hodnoty \"yes\" (termínovaný vklad sjednán) a \"no\" (termínovaný vklad nebyl sjednán).\n",
    "\n",
    "Soubor obsahuje 41188 pozorování. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popis proměnných: \n",
    "Numerické proměnné\n",
    "- 1 - Age: Věk klienta v letech.\n",
    "- 2 - Balance: Zůstatek na účtu klienta (v eurech).\n",
    "- 3 - Day: Den v měsíci, kdy byl poslední kontakt s klientem.\n",
    "- 4 - Duration: Délka posledního telefonického kontaktu (v sekundách).\n",
    "- 5 - Campaign: Počet kontaktů s klientem během aktuální marketingové kampaně.\n",
    "- 6 - Pdays: Počet dní od posledního kontaktu (999 znamená, že klient byl nikdy předtím nekontaktován).\n",
    "- 7 - Previous: Počet kontaktů s klientem před aktuální kampaní.\n",
    "- 8 - Emp.var.rate: Míra zaměstnanecké variability v posledním čtvrtletí (v procentech).\n",
    "- 9 - Cons.price.idx: Index cen spotřebitelů (v posledním měsíci).\n",
    "- 10 - Cons.conf.idx: Index důvěry spotřebitelů (v posledním měsíci).\n",
    "\n",
    "Kategorické proměnné\n",
    "- 11 - Job: Typ zaměstnání klienta (např. zaměstnanec, důchodce, podnikatel atd.).\n",
    "- 12 - Marital: Rodinný stav klienta (např. svobodný, ženatý, rozvedený).\n",
    "- 13 - Education: Vzdělání klienta (např. základní, střední, vysokoškolské).\n",
    "- 14 - Default: Zda má klient úvěrové selhání (ano/ne).\n",
    "- 15 - Housing: Zda má klient hypotéku (ano/ne).\n",
    "- 16 - Loan: Zda má klient osobní půjčku (ano/ne).\n",
    "- 17 - Contact: Způsob kontaktu (např. mobilní, pevná linka).\n",
    "- 18 - Month: Měsíc posledního kontaktu (např. leden, únor atd.).\n",
    "- 19 - Weekday: Den v týdnu posledního kontaktu (např. pondělí, úterý).\n",
    "- 20 - Poutcome: Výsledek předchozí marketingové kampaně (např. úspěšná, neúspěšná, žádná).\n",
    "\n",
    "Cílová proměnná \n",
    "Subscription: Binární proměnná indikující, zda klient podepsal termínovaný vklad (ano/ne).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PŘEDZPRACOVÁNÍ DAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Získání souhrnných statistik pro data\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# Zde vidíme, kolik hodnot a jakého typu proměnná je "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace cílové proměnné \n",
    "plt.figure(figsize=(6, 4))\n",
    "df['y'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Podepsal klient termínovaný vklad?')\n",
    "plt.xlabel('y - cílová proměnná  ')\n",
    "plt.ylabel('Počet klientů')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Zobrazení histogramu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace vstupujících proměnných \n",
    "fig = plt.figure(figsize=(20,20))\n",
    "cols = list(df.columns)\n",
    "cols.remove(\"y\")\n",
    "\n",
    "for i, name in enumerate(cols):\n",
    "    x = fig.add_subplot(5,4,i+1)\n",
    "    if (df[name].dtype==\"object\"):\n",
    "        x.bar(df[name].sort_values().unique(), df[name].value_counts())\n",
    "    else:\n",
    "        x.hist(df[name])\n",
    "    x.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ošetření chybějících hodnot - je nutné nahradit hodnoty \"unknown\" hodnotami NA \n",
    "\n",
    "df2=df.replace(to_replace=\"unknown\",value=pd.NA)\n",
    "df2[\"pdays\"]=df2[[\"pdays\"]].replace(to_replace=999,value=np.nan)\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nyní můžeme zjistit pro každý sloupec chybějící hodnoty a jejich počet\n",
    "na=df2.isnull()\n",
    "na.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korelace \n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Vytvoření korelační matice\n",
    "correlation_matrix = df_encoded.corr()\n",
    "\n",
    "# Vizualizace korelace mezi proměnnými v datasetu pomocí heatmapy\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Korelační matice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozdělení věku do intervalů\n",
    "age_bins = [17, 29, 39, 49, 64, 98]\n",
    "age_labels = ['17-29', '30-39', '40-49', '50-64', '65+']\n",
    "df2['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na základě informací o datovém souboru a chybějících proměnných jsme se rozhodli z analýzy vyřadit \"contact\", protože pro výsledek není relevantiní zda byl kontaktován přes pevnou linku nebo mobilní telefon. \n",
    "Pro velké množství chybějících pozorování odstraníme také proměnnou \"poutcome\". \n",
    "Pro analýzu je nutné také odstranit proměnnou \"nr.employed\", protože hodnota je získána až po realizaci telefonního hovoru a ovlivňuje cílovou proměnnou. Pokud dosahuje nr.employed hodnoty 0, pak cílová proměnná = \"no\". A sloupec age, který je nahrazen novým sloupcem age_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odstranění nepotřebných sloupců\n",
    "df2=df2.drop([\"pdays\", \"duration\", \"nr.employed\",\"poutcome\",\"contact\", \"age\"],axis=1)\n",
    "df2.head(10) # Zobrazení dat pro kontrolu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset neobsahuje také úplné informace o čase, pozorování jsou však sesbírána chronologicky. Vytvoříme novou proměnnou \"year\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření nové proměnné year\n",
    "df2[\"year\"] = 2008\n",
    "add_year = 0\n",
    "months = [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n",
    "actual_month = df2.loc[0, \"month\"]  \n",
    "\n",
    "for i in df2.index:\n",
    "    if (months.index(actual_month) > months.index(df2.loc[i, \"month\"])):\n",
    "        add_year += 1  \n",
    "    df2.loc[i, \"year\"] += add_year\n",
    "    actual_month = df2.loc[i, \"month\"]  \n",
    "\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření nových intervalů pro proměnné \"previous\" a \"campaign\"\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "ax1.bar(df[\"previous\"].sort_values().unique(), df[\"previous\"].value_counts())\n",
    "ax1.set_title('Boxplot of attribute \"previous\"')\n",
    "ax2.bar(df[\"campaign\"].sort_values().unique(), df[\"campaign\"].value_counts())\n",
    "ax2.set_title('Boxplot of attribute \"campaign\"')\n",
    "\n",
    "fig.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"previous_cat\"] = pd.cut(df2.previous, bins=[-1, 0, 2, 1000], labels=[\"0\", \"1-2\", \"3+\"])\n",
    "df2[\"campaign_cat\"] = pd.cut(df2.campaign, bins=[-1, 0, 1, 2, 3, 4, 10, 1000], labels=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5-10\", \"10+\"])\n",
    "#df2.head\n",
    "# Zobrazení prvních několika řádků s novými kategoriemi\n",
    "#print(df2[[\"previous\", \"previous_cat\", \"campaign\", \"campaign_cat\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizace vybraných numerických sloupců\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_columns = ['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "df2[numeric_columns] = scaler.fit_transform(df2[numeric_columns])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Vytvoření kopie datasetu\n",
    "df_cleaned = df2.copy() \n",
    "print(df_cleaned.dtypes)\n",
    "# Uložení vyčištěného datasetu do CSV souboru\n",
    "df_cleaned.to_csv(\"data_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oddělení atributů (features) a cílové proměnné (target)\n",
    "X = df_cleaned.drop(columns=['y'])  # Všechny sloupce kromě 'y' - vstupní proměnné\n",
    "y = df_cleaned['y'].values  # Cílová proměnná\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření proměnných feature_cols a odstranění cílové proměnné 'y', aby zůstaly pouze proměnné, které se budou používat jako vstupy do modelu\n",
    "feature_cols = list(df_cleaned.columns)\n",
    "feature_cols.remove(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozdělení dat na trénovací a testovací\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 20% testovací, 80% trénovací. Random state znamená, že při každém stuštění bude stejné rozložení dat\n",
    "\n",
    "# Výpis velikosti trénovací a testovací sady\n",
    "print(\"Počet záznamů v trénovací sadě:\", X_train.shape[0])\n",
    "print(\"Počet záznamů v testovací sadě:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Řešení missing values - nahrazení NaN hodnot nejčastějšími hodnotami (mód)\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == \"object\" or X_train[col].dtype == \"category\":\n",
    "        mode_value = X_train[col].mode()[0]  # Získání módu\n",
    "        X_train[col] = X_train[col].fillna(mode_value)\n",
    " \n",
    "        \n",
    "\n",
    "print(X_train)\n",
    "na3=X_train.isnull()\n",
    "na3.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Řešení missing values - nahrazení NaN hodnot nejčastějšími hodnotami (mód)\n",
    "\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].dtype == \"object\" or X_test[col].dtype == \"category\":\n",
    "        mode_value = X_test[col].mode()[0]  # Získání módu\n",
    "        X_test[col] = X_train[col].fillna(mode_value) \n",
    "        \n",
    "\n",
    "print(X_test)\n",
    "\n",
    "na4=X_test.isnull()\n",
    "na4.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Převod proměnných typu object nebo category na číselné hodnoty 0 = no, 1 = yes a kategorizace  \n",
    "\n",
    "# Slovník pro uložení kódovníků\n",
    "kodovniky = {}\n",
    "\n",
    "# Funkce pro faktorizaci s ohledem na kódovníky\n",
    "def factorize_with_dict(df, kodovniky):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\" or df[col].dtype.name == \"category\":\n",
    "            if col not in kodovniky:\n",
    "                # Vytvoření nového kódovníku, pokud neexistuje\n",
    "                codes, uniques = pd.factorize(df[col])\n",
    "                kodovniky[col] = dict(enumerate(uniques, 1))  # +1 pro začátek od 1\n",
    "                df[col] = codes + 1\n",
    "            else:\n",
    "                # Použití existujícího kódovníku pro konzistenci\n",
    "                df[col] = df[col].map({v: k for k, v in kodovniky[col].items()})\n",
    "        else:\n",
    "            df[col] = df[col]\n",
    "    return df\n",
    "\n",
    "# Faktorizace X_train s uložením kódovníků\n",
    "X_train = factorize_with_dict(X_train, kodovniky)\n",
    "\n",
    "# Faktorizace X_test s použitím stejných kódovníků\n",
    "X_test = factorize_with_dict(X_test, kodovniky)\n",
    "\n",
    "# Výpis všech kódovníků\n",
    "for col, kodovnik in kodovniky.items():\n",
    "    print(f\"Kódovník pro sloupec '{col}': {kodovnik}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Převedení y_train a y_test pro binární hodnoty pomocí np.where\n",
    "y_train = np.where(y_train == \"yes\", 1, 0)\n",
    "y_test = np.where(y_test == \"yes\", 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyrovnání tříd (class balancing) na trénovacích datech a srovnání technik: \n",
    "- under_sampler - odstraní některé vzorky z většinové třídy, aby se snížil její počet a vyrovnal se s menšinovou třídou\n",
    "- smote_sampler - vytváří syntetické vzorky pro menšinovou třídu, což zvyšuje její zastoupení\n",
    "- over_sampler - opakuje vzorky menšinové třídy, čímž zvyšuje jejich počet a vyrovnává třídy\n",
    "\n",
    "Po srovnání všech výsledků jsme se rozhodly využít over_sampler, který vychází nejlépe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#under_sampler = RandomUnderSampler(random_state = 42)\n",
    " \n",
    "#X_train2, y_train2 = under_sampler.fit_resample(X_train, y_train)\n",
    "#print(f\"Training target statistics: {Counter(y_train2)}\")\n",
    "#print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    " \n",
    "#Training target statistics: Counterr({0: 3705, 1: 3705}) \n",
    "#Testing target statistics: Counter({0: 7303, 1: 935})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE_sampler = SMOTE(random_state = 42)\n",
    "\n",
    "#X_train2, y_train2 = SMOTE_sampler.fit_resample(X_train, y_train)\n",
    "#print(f\"Training target statistics: {Counter(y_train2)}\")\n",
    "#print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    " \n",
    "#Training target statistics: Counter({0: 29245, 1: 29245})\n",
    "#Testing target statistics: Counter({0: 14623, 1: 1853})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampler  = RandomOverSampler(random_state=42)\n",
    " \n",
    "X_train2, y_train2 = over_sampler.fit_resample(X_train, y_train)\n",
    "print(f\"Training target statistics: {Counter(y_train2)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "\n",
    "#Training target statistics: Counter(0): 29245, (1): 29245})\n",
    "#Testing target statistics: Counter((0): 7303, (1): 935})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## MODELOVÁNÍ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL LOGISTICKÉ REGRESE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Využíváme data, která jsme získaly z over_sampler\n",
    "X_train2\n",
    "y_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model logistické regrese s maximálním počtem iterací 10.000\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train2, y_train2) #Trénování modelu na trénovacích datech\n",
    "y_pred_logreg = logreg.predict(X_test) # Provedení predikce na základě testovacích dat\n",
    "y_prob_log = logreg.predict_proba(X_test)[:,1] # Získává pravděpodobnosti pro pozitivní třídu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model logistické regrese s křížovou validací\n",
    "logreg_cv = LogisticRegressionCV(cv = 5, Cs= 1, scoring = \"accuracy\", max_iter = 10000)\n",
    "logreg_cv.fit(X_train2,y_train2) #Trénování modelu na trénovacích datech\n",
    "y_pred_log_cv = logreg_cv.predict(X_test) # Provedení predikce na základě testovacích dat\n",
    "y_prob_log_cv = logreg_cv.predict_proba(X_test)[:,1] # Získává pravděpodobnosti pro pozitivní třídu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ROZHODOVACÍHO STROMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model rozhodovacího stromu\n",
    "decision_tree = DecisionTreeClassifier(max_depth = 3)\n",
    "model_tree = decision_tree.fit(X_train2, y_train2) #Trénování modelu na trénovacích datech\n",
    "predictions_tree = model_tree.predict(X_test) # Provedení predikce na základě testovacích dat\n",
    "accuracy_score(y_test, predictions_tree) # Vypočátíní přesnosti modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření slovníku pro uchování feature_name a feature_importance\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(feature_cols, model_tree.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "# Měření významnosti jednotlivých proměnných (features) - Gini-importance    \n",
    "# Vytváří DataFrame pro důležitosti proměnných a vykresluje je jako sloupcový graf\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances.sort_values(by='Gini-importance').plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model rozhodovacího stromu s křížovou validací \n",
    "# Definuje rozsah hyperparametrů pro hledání rozhodovací strom\n",
    "param_dist = {\"max_depth\":(3,4,5,6,7,8,9,10),\"min_samples_leaf\":(1,2,3,4,5),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Ladění hyperparametrů pomocí GridSearchCV\n",
    "model_tree_cv = GridSearchCV(model_tree, param_dist, cv=5)\n",
    "model_tree_cv.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trénování a predikce s nejlepším modelem, který jsme našly na základě kroku výše\n",
    "model_tree_best = DecisionTreeClassifier( criterion='entropy', max_depth= 4, min_samples_leaf=4) # Nejlepší hyperparametry, které jsme našly pomocí GridSearchCV\n",
    "model_tree_best.fit(X_train2,y_train2) #Trénování modelu na trénovacích datech\n",
    "predictions_tree2 = model_tree_best.predict(X_test)\n",
    "accuracy_score(y_test, predictions_tree2) # Vypočítání přesnosti modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manuálně nastavený rozhodovací strom a jeho vizualizace\n",
    "plt.figure(figsize=(18,18))\n",
    "plot_tree(model_tree,feature_names = list(X_train2.columns), \n",
    "               class_names=[\"no\",\"yes\"],\n",
    "            filled = True,fontsize=10)  \n",
    "matplotlib.pyplot.savefig('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace rozhodovacho stromu, který jsme získaly pomocí optimalizace s GridSearchCV\n",
    "plt.figure(figsize=(18,18))\n",
    "plot_tree(model_tree_best,feature_names = list(X_train2.columns), \n",
    "               class_names=[\"no\",\"yes\"],\n",
    "            filled = True,fontsize=10)  \n",
    "matplotlib.pyplot.savefig('tree2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření modelu náhodného lesa\n",
    "model_forest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "model_forest.fit(X_train2, y_train2) # Trénování modelu na trénovacích datech\n",
    "predictions_forest = model_forest.predict(X_test) # Provedení predikce na základě testovacích dat\n",
    "accuracy_score(y_test, predictions_forest) # Vypočítání přesnosti modelu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření matice záměn pro hodnocení výkonu klasifikačního modelu\n",
    "confmatrix=confusion_matrix(y_test, predictions_forest)\n",
    "print(confmatrix)\n",
    "ConfusionMatrixDisplay.from_estimator(model_forest, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnocení matice záměn: \n",
    "- TN (6.272): Počet případů, kdy model správně předpověděl třídu „ne“ (negativní) a skutečnost byla také „ne“.\n",
    "- FP (1.031): Počet případů, kdy model nesprávně předpověděl třídu „ano“, ale skutečnost byla „ne“. \n",
    "- FN (376): Počet případů, kdy model nesprávně předpověděl třídu „ne“, ale skutečnost byla „ano“. \n",
    "- TP (559): Počet případů, kdy model správně předpověděl třídu „ano“ a skutečnost byla také „ano“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest  s křížovou validací\n",
    "# Ladění nejlepších hyperparametrů pomocí GridSearchCV\n",
    "parametergrid= {\"criterion\" : (\"gini\", \"entropy\"),\"max_depth\":(1,2,3,4,5),\"min_samples_leaf\":(1,2,3,4,5)\n",
    "}\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parametergrid) # Provedení 5ti násobné křížové validace\n",
    "clf.fit(X_train2, y_train2)\n",
    "best_model=clf.best_estimator_ # Nejlepší model nalezený metodou GridSearchCV\n",
    "best_params=clf.best_params_ # Nejlepší parametry tohoto modelu\n",
    "best_score=clf.best_score_ # Nejlepší dosažené skóre\n",
    "\n",
    "print(\"Nejlepší model:\", best_model)\n",
    "print(\"Nejlepší parametry:\", best_params)\n",
    "print(\"Nejlepší skóre:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trénování a predikce s nejlepším modelem, který jsme našly na základě kroku výše\n",
    "model_forest_best = RandomForestClassifier( criterion= 'entropy', max_depth= 5, min_samples_leaf=2)\n",
    "model_forest_best.fit(X_train2,y_train2) # Trénování modelu na trénovacích datech\n",
    "predictions_forest2 = model_forest.predict(X_test) # Provedení predikce na základě testovacích dat\n",
    "accuracy_score(y_test, predictions_forest2) # Vypočátíní přesnosti modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## VYHODNOCENÍ A POROVNÁNÍ MODELŮ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porovnání logistické regrese a logistické regrese s křížovou validací"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vyhodnocení modelu print(\"Logistická Regrese:\")\n",
    "print(\"Přesnost:\", accuracy_score(y_test, y_pred_logreg)) # Vypočítá procento správných predikcí z celkového počtu -> přesnost modelu\n",
    "print(classification_report(y_test, y_pred_logreg)) # Vypočítání metrik - precision, recall, f1-score, support\n",
    "print(\"Koeficienty:\", logreg.coef_)\n",
    "print(\"Intercept:\", logreg.intercept_)\n",
    "\n",
    "# Vyhodnocení modelu print(\"Logistická RegreseCV:\")\n",
    "print(\"Přesnost:\", accuracy_score(y_test, y_pred_log_cv)) # Vypočítá procento správných predikcí z celkového počtu\n",
    "print(classification_report(y_test, y_pred_log_cv)) # Vypočítání metrik - precision, recall, f1-score, support\n",
    "print(\"Koeficienty:\", logreg_cv.coef_) # Výpis koeficientů \n",
    "print(\"Intercept:\", logreg_cv.intercept_) # Výpis intercept modelu - hodnota, kde model předpokládá, že výstup bude nula, když jsou všechny vstupní proměnné nulové\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Výsledky logictické regrese\n",
    "- Přesnost modelu (accuracy): 74 %.\n",
    "- Precision pro třídu 0 (ne): 95 % (z klientů, které model klasifikoval jako „ne, neuzavřou vklad“, bylo 95 % skutečně správných). Za to přesnost pro třídu 1 byla pouze 26 %. \n",
    "- Recall pro třídu 1 (ano): 69 % (model správně rozpoznal 69 % klientů, kteří uzavřeli vklad).\n",
    "- F1-score: 0.83 pro třídu 0 a 0.37 pro třídu 1, což naznačuje, že model je velmi dobrý v klasifikaci třídy 0, ale slabší v klasifikaci třídy 1.\n",
    "### Výsledky logictické regrese s křížovou validací\n",
    "- Přesnost modelu (accuracy): 73 %.\n",
    "- Precision pro třídu 0 (ne): 95 % (z klientů, které model klasifikoval jako „ne“, bylo 95 % skutečně správných).\n",
    "- Recall pro třídu 1 (ano): 70 % (model správně rozpoznal 70 % klientů, kteří uzavřeli vklad).\n",
    "- F1-score: 0.83 pro třídu 0 a 0.37 pro třídu 1, což naznačuje, že model je velmi dobrý v klasifikaci třídy 0, ale slabý v klasifikaci třídy 1.\n",
    "### Shrnutí\n",
    "Obě verze modelu vykazují podobné výsledky a dosahují celkové přesnosti 73-74 %. Mají velmi dobrou precision pro třídu 0 - 95 % - dobře předpovádají, že klient neuzavře termínovaný vklad. Recall (citlivost) je u obou modelů 73 - 74 %, což znamená, že modely zachytí skoro tři čtvrtiny všech případů této třídy 0. U třídy 1 jsou modely málo precizní a mají i vysokou míru falešných pozitiv. To znamená obtíže s predikcí klientů, kteří uzavřou vklad a naopak modely lépe klasifikují klienty, kteří vklad neuzavřou. Z hlediska výsledků jsou oba modely skoro totožné, v případě modelu bez křížové validace vychází některé ukazatele lépe jen o 1 %.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porovnání logistické regrese a logistické regrese s křížovou validací\n",
    "# Zobrazení intercept a koeficientů\n",
    "print(\"Logistická Regrese:\")\n",
    "print(\"Intercept:\", round(logreg.intercept_[0], 3))\n",
    "for i, name in enumerate(feature_cols):\n",
    "    print(name,\": \",round(logreg.coef_[0,i],3))\n",
    "\n",
    "\n",
    "print(\"Logistická RegreseCV:\")\n",
    "print(\"Intercept:\", round(logreg_cv.intercept_[0], 3))\n",
    "for i, name in enumerate(feature_cols):\n",
    "    print(name,\": \", round(logreg_cv.coef_[0,i],3))\n",
    "\n",
    "print(\"\\nIndividual fold scores: \\n\")\n",
    "for i in range(5):\n",
    "    print(i+1, \": \", round(logreg_cv.scores_[1][i][0], 5))\n",
    "    \n",
    "print (\"The average score was: \", round(np.average(logreg_cv.scores_[1]),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Oba modely mají podobné hodnoty interceptu, velice blázko 0. To unamená, že při nulových hodnotách vysvětlujícíh proměnných nemá model vychýlenou pravděpodobnost k třídě 0 nebo 1 ( neuzavření či uzavření vkladu)\n",
    "- Koeficienty se mezi modely mírně liší. To naznačuje konzistentní vliv jednotlivých proměnných a modely stabilně identifikují podobný vliv pro všechny proměnné, bez ohledu na použití křížové validace\n",
    "- Výsledky pro jednotlivé foldy a jejich score se pohybují od 0.72294 do 0.72594. To znamená, že model má stabilní výkonnost napříč různými částmi dat.\n",
    "\n",
    "- **Shrnutí** : Logistická regrese s křížovou validací vykazuje stabilní výkon, ale nepřináší výrazné zlepšení přesnosti oproti běžné logistické regresi. Průměrné skóre v jednotlivých folech ukazuje konzistenci modelu na různých částech dat, což je výhodné pro jeho robustnost. Rozdíly v koeficientech mezi modely jsou minimální, což naznačuje, že vliv jednotlivých proměnných na predikci je obdobný v obou případech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Výpis klíčových metrik a matice záměn pro logistickou regresi\n",
    "print(\"Logistic Model - manual\")\n",
    "print(\"Classification report: \\n\", classification_report(y_test, y_pred_logreg)) # Výpis klíčových metrik\n",
    "# Vytvoření matice záměn\n",
    "print(\"Confussion matrix\") \n",
    "mat  =confusion_matrix(y_test, y_pred_logreg)\n",
    "conf_mat=pd.DataFrame({\"True 0\":[mat[0][0], mat[1][0]],\n",
    "                 \"True 1\":[mat[0][1], mat[1][1]]})\n",
    "conf_mat.index = [\"Predicted 0\", \"Predicted 1\"]\n",
    "print(conf_mat, \"\\n\")\n",
    "\n",
    "# Výpis klíčových metrik a matice záměn pro logistickou regresi s křížovou validací\n",
    "print(\"Logistic Model - cross validation\")\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test, y_pred_log_cv))\n",
    "print(\"Confussion matrix\")\n",
    "mat  =confusion_matrix(y_test, y_pred_log_cv)\n",
    "conf_mat=pd.DataFrame({\"True 0\":[mat[0][0], mat[1][0]],\n",
    "                 \"True 1\":[mat[0][1], mat[1][1]]})\n",
    "conf_mat.index = [\"Predicted 0\", \"Predicted 1\"]\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC křivka\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_prob_log)\n",
    "fpr2, tpr2, thresholds2 = roc_curve(y_true=y_test, y_score=y_prob_log_cv)\n",
    "\n",
    "# Vykreslení ROC křivky\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Náhodný klasifikátor')\n",
    "plt.plot(fpr, tpr, label='Manuální hyperparametry')\n",
    "plt.plot(fpr2, tpr2, label='Křížová validace (best params)')\n",
    "\n",
    "# Nastavení grafu\n",
    "plt.xlabel('Falešná pozitivní míra (FPR)')\n",
    "plt.ylabel('Pravdivá pozitivní míra (TPR)')\n",
    "plt.title('ROC křivka Random Forest Classifier')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretace výsledků ROC křivky pro model logistické regrese\n",
    "\n",
    "- **Modrá linie** - Představuje model logistické regrese, který byl nastaven s ručně laděnými hyperparametry. Vidíme, že jeho výkon je vyšší než náhodný klasifikátor, protože leží nad černou přerušovanou čarou.\n",
    "- **Oranžová linie** - Představuje model logistické regrese s hyperparametry optimalizovanými křížovou validací. Oranžová linie je podobná modré, v průběhu místy mírně zaostává oproti modré linii, ale většinou je na podobné úrovni jako modrá linie.\n",
    "- Oba modely jsou lepší než náhodný klasifikátor (černá přerušovaná čára). Jsou schopny lépe rozlišovat mezi pozitivními a negativními případy než náhodné tipování.\n",
    "- Původní model logistické regrese si vede o trochu lépe, než laděný model křížovou validací. V tomto případě nevedla křížová validace ke zlepšení výkonu modelu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porovnání rozhodovacího stromu a rozhodovacího stromu s křížovou validací"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Manuálně nastavený decisiontree \\n\")\n",
    "print(classification_report(y_test, predictions_tree))  # Vypočítání metrik - precision, recall, f1-score, support\n",
    "print(accuracy_score(y_test, predictions_tree), \"\\n\") # Vypočítá procento správných predikcí z celkového počtu\n",
    "# confusion_matrix - Zobrazuje počet skutečných pozitivních a negativních případů v porovnání s predikcemi.\n",
    "mat  =confusion_matrix(y_test, predictions_tree)\n",
    "conf_mat=pd.DataFrame({\"True 0\":[mat[0][0], mat[1][0]],\n",
    "                 \"True 1\":[mat[0][1], mat[1][1]]})\n",
    "conf_mat.index = [\"Predicted 0\", \"Predicted 1\"]\n",
    "print(conf_mat, \"\\n\")\n",
    "\n",
    "print(\"Decision tree pomocí GridSearchCV \\n\")\n",
    "print(classification_report(y_test, predictions_tree2))  # Vypočítání metrik - precision, recall, f1-score, support\n",
    "print(accuracy_score(y_test, predictions_tree2),\"\\n\") # Vypočítá procento správných predikcí z celkového počtu\n",
    "# confusion_matrix - Zobrazuje počet skutečných pozitivních a negativních případů v porovnání s predikcemi.\n",
    "mat  =confusion_matrix(y_test, predictions_tree2)\n",
    "conf_mat=pd.DataFrame({\"True 0\":[mat[0][0], mat[1][0]],\n",
    "                 \"True 1\":[mat[0][1], mat[1][1]]})\n",
    "conf_mat.index = [\"Predicted 0\", \"Predicted 1\"]\n",
    "print(conf_mat, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Výsledky manuálně nastaveného Decision Tree:\n",
    "- Přesnost (accuracy): 83,10 %.\n",
    "- Precision pro třídu 0 (ne): 94 % (z klientů, které model klasifikoval jako „ne“, bylo 94 % skutečně správných).\n",
    "- Recall pro třídu 1 (ano): 59 % (model správně rozpoznal 59 % klientů, kteří uzavřeli vklad s 35% precision).\n",
    "- F1-score: 0.90 pro třídu 0 a 0.44 pro třídu 1. Model dobře klasifikuje třídu 0, ale má slabší výkon pro třídu 1.\n",
    "\n",
    "Matice záměn:\n",
    "- Model správně klasifikoval 6301 případů třídy 0 a 547 případů třídy 1.\n",
    "- Model chybně klasifikoval 1002 negativních případů jako pozitivní a 388 pozitivních případů jako negativní.\n",
    "\n",
    "### Výsledky modelu vyladěného pomocí GridSearchCV:\n",
    "- Přesnost (accuracy): 82,9 % (velmi podobná manuálně nastavenému modelu).\n",
    "- Precision, recall a F1-score jsou stejné jako u manuálně nastaveného modelu. Liší se pouze recall pro 1. třídu o 1 %.\n",
    "\n",
    "Matice záměn:\n",
    "- Model správně klasifikoval 6271 případů třídy 0 a 559 případů třídy 1.\n",
    "- Chybně klasifikoval 1032 negativních případů jako pozitivní a 376 pozitivních případů jako negativní.\n",
    "  \n",
    "### Srovnání výsledků:\n",
    "- Přesnost (accuracy) obou modelů je téměř totožná: 83,10 % pro manuálně nastavený model a 82,9 % pro GridSearchCV model.\n",
    "- Precision a recall jsou stejné pro oba modely, což znamená, že ladění hyperparametrů GridSearchCV nepřineslo žádné zlepšení v porovnání s manuálně nastaveným modelem.\n",
    "- F1-score pro třídu 0 je vysoké (0.90), ale pro třídu 1 je nižší (0.44). To znamená, že modely lépe rozpoznávají třídu 0 (klienty, kteří vklad neuzavřou) než třídu 1.\n",
    "- GridSearchCV model má mírně lepší schopnost klasifikovat třídu 1 (559 správných predikcí oproti 547 u manuálního modelu), ale zhoršuje se u třídy 0 (6271 správných vs. 6301 u manuálního modelu).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porovnání manuálně nastaveného Random Forest modelu a modelu, který byl vyladěn pomocí GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porovnání manuálně nastaveného Random Forest modelu a modelu, který byl vyladěn pomocí GridSearchCV\n",
    "print(\"Manuálně nastavený Random forest\\n\")\n",
    "print(classification_report(y_test, predictions_forest)) # Vypočítání metrik - precision, recall, f1-score, support\n",
    "print(accuracy_score(y_test, predictions_forest),\"\\n\") # Vypočítá procento správných predikcí z celkového počtu\n",
    "# confusion_matrix - Zobrazuje počet skutečných pozitivních a negativních případů v porovnání s predikcemi.\n",
    "mat  =confusion_matrix(y_test, predictions_forest)\n",
    "conf_mat=pd.DataFrame({\"True 0\":[mat[0][0], mat[1][0]],\n",
    "                 \"True 1\":[mat[0][1], mat[1][1]]})\n",
    "conf_mat.index = [\"Predicted 0\", \"Predicted 1\"]\n",
    "print(conf_mat, \"\\n\")\n",
    "\n",
    "print(\" Random forest pomocí GridSearchCV \\n\")\n",
    "print(classification_report(y_test, predictions_forest2)) # Vypočítání metrik - precision, recall, f1-score, support\n",
    "print(accuracy_score(y_test, predictions_forest2),\"\\n\") # Vypočítá procento správných predikcí z celkového počtu\n",
    "# confusion_matrix - Zobrazuje počet skutečných pozitivních a negativních případů v porovnání s predikcemi.\n",
    "mat  =confusion_matrix(y_test, predictions_forest2)\n",
    "conf_mat=pd.DataFrame({\"True 0\":[mat[0][0], mat[1][0]],\n",
    "                 \"True 1\":[mat[0][1], mat[1][1]]})\n",
    "conf_mat.index = [\"Predicted 0\", \"Predicted 1\"]\n",
    "print(conf_mat, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Výsledky manuálně nastaveného modelu Random forest :\n",
    "- Přesnost (accuracy): 82,9 %.\n",
    "- Precision pro třídu 0 (ne): 94 % (z klientů, které model klasifikoval jako „ne“, bylo 94 % skutečně správných).\n",
    "- Recall pro třídu 1 (ano): 60 % (model správně rozpoznal 60 % klientů, kteří uzavřeli vklad s 35% precision).\n",
    "- F1-score: 0.90 pro třídu 0 a 0.44 pro třídu 1 znamená, že model je velmi dobrý v klasifikaci třídy 0, ale slabší v klasifikaci třídy 1.\n",
    "\n",
    "Matice záměn:\n",
    "- Model správně předpověděl 6272 negativních případů a 559 pozitivních případů.\n",
    "- Chybně klasifikoval 1031 negativních případů jako pozitivní a 376 pozitivních případů jako negativní. \n",
    "\n",
    "### Výsledky modelu náhodného lesa vyladěného pomocí GridSearchCV:\n",
    "- Přesnost (accuracy): 82,9 % (stejná jako u manuálního modelu).\n",
    "- Precision, recall a F1-score jsou také shodné s manuálním modelem.\n",
    "  \n",
    "Matice záměn je stejná jako u manuálního modelu a ladění hyperparametrů nemělo žádný dopad na výkonnost modelu.\n",
    "\n",
    "### Shrnutí:\n",
    "- Oba modely mají vysokou přesnost při predikci třídy 0 (neuzavření vkladu), ale jsou méně přesné a citlivé při predikci třídy 1 (uzavření vkladu).\n",
    "- Ladění hyperparametrů pomocí GridSearchCV nemělo v tomto případě žádný vliv na zlepšení výkonu modelu, protože oba modely mají totožné výsledky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Závěr:\n",
    "Všechny modely excelují v klasifikaci třídy 0 (neuzavření vkladu), ale mají problémy s predikcí třídy 1 (uzavření vkladu).\n",
    "Křížová validace zlepšuje schopnost modelů generalizovat na nových datech, ale v některých případech (např. u náhodného lesa a rozhodovacího stromu) nepřináší žádné zlepšení výkonnosti.\n",
    "Ladění hyperparametrů pomocí GridSearchCV nemělo v žádném případě zásadní vliv na zlepšení výsledků oproti manuálně nastaveným modelům.\n",
    "Pro zlepšení výsledků by bylo vhodné přistoupit k pokročilým metodám jako jsou gradient boosting modely nebo modely optimalizovat více na recall pro třídu 1.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
